{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3aef81-771e-45ef-b5f1-3f976396e3d2",
   "metadata": {},
   "source": [
    "## Exteval Corrector Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b1a9c2-323e-4ea6-ae15-da66d324e3fc",
   "metadata": {},
   "source": [
    "### Step 1: Extract human annotated incorrect summaries from the total 1600 summaries (`data.json`)\n",
    "\n",
    "To archieve this the following script will filter the `data.json` and create a `data_only_incorrect.json` with all summaries that contain errors that were detected by humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80a5478-7c92-4ad9-8d42-2c2f9e97c3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data was saved in 'data/data_only_incorrect.json'.\n",
      "Total number of entries in the filtered JSON: 535\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_file = \"data/data.json\"\n",
    "output_file = \"data/data_only_incorrect.json\"\n",
    "\n",
    "fields_to_check = [\n",
    "    \"incorrect_coref\",\n",
    "    \"incomplete_coref\",\n",
    "    \"incorrect_discourse\",\n",
    "    \"incomplete_discourse\",\n",
    "    \"misleading1\",\n",
    "    \"misleading2\",\n",
    "]\n",
    "\n",
    "# Load the input JSON file\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Filter the data based on the specified fields\n",
    "filtered_data = {\n",
    "    key: value\n",
    "    for key, value in data.items()\n",
    "    if any(value.get(field, \"no\") == \"yes\" for field in fields_to_check)\n",
    "}\n",
    "\n",
    "# Save the filtered data to the output file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(filtered_data, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Count the total number of entries in the filtered JSON\n",
    "total_entries = len(filtered_data)\n",
    "\n",
    "# Output the total count and the saved file message\n",
    "print(f\"Filtered data was saved in '{output_file}'.\")\n",
    "print(f\"Total number of entries in the filtered JSON: {total_entries}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93257cf3-9c43-4b23-84b5-190b7b994b82",
   "metadata": {},
   "source": [
    "### Step 2: Run ExtEval on the summaries to see the exact scores it predicts for `data_only_incorrect.json`\n",
    "\n",
    "These scores will be saved in `data_only_incorrect_exteval.json` and are needed for the prompt to `GPT-4o` and later for the `Evaluation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceeea3e6-a0d0-4494-b747-48242c551a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command executed successfully.\n",
      "Downloading https://storage.googleapis.com/allennlp-public-mo… ━━━ 100% 0:… 1.3…\n",
      "                                                                            GB  \n",
      "927.3197152614594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the command and its arguments\n",
    "command = [\n",
    "    \"python3\",\n",
    "    \"exteval/exteval.py\",\n",
    "    \"--data_file\", \"data/data_only_incorrect.json\",\n",
    "    \"--output_file\", \"data/scores/data_only_incorrect_exteval.json\"\n",
    "]\n",
    "\n",
    "# Execute the command\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "# Print the output and errors\n",
    "if result.returncode == 0:\n",
    "    print(\"Command executed successfully.\")\n",
    "    print(result.stdout)\n",
    "else:\n",
    "    print(\"Error occurred while executing the command.\")\n",
    "    print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ac0dec-03b8-4680-a831-1530d6baa37b",
   "metadata": {},
   "source": [
    "### Step 2b: Run ExtEval modified on the summaries to see the exact scores it predicts for `data_only_incorrect.json` witd extended information for the found errors\n",
    "\n",
    "These scores will be saved in `data_only_incorrect_exteval_modified.json` and are needed for the prompt to `GPT-4o` and later for the `Evaluation`.\n",
    "The new exteval modified will provide a lot more information for `GPT-4o` and will ensure a better correction later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3b86db0-338f-46f1-a87e-416ed6b48435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command executed successfully.\n",
      "1391.9829301834106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the command and its arguments\n",
    "command = [\n",
    "    \"python3\",\n",
    "    \"exteval/extevalModified.py\",\n",
    "    \"--data_file\", \"data/data_only_incorrect.json\",\n",
    "    \"--output_file\", \"data/scores/data_only_incorrect_exteval_modified.json\"\n",
    "]\n",
    "\n",
    "# Execute the command\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "# Print the output and errors\n",
    "if result.returncode == 0:\n",
    "    print(\"Command executed successfully.\")\n",
    "    print(result.stdout)\n",
    "else:\n",
    "    print(\"Error occurred while executing the command.\")\n",
    "    print(result.stderr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850b95b7-c3a9-4f2e-804b-1d1daed5f1d6",
   "metadata": {},
   "source": [
    "### Step 3: Combine incorrect data (`data_only_incorrect.json`) with their exteval scores (`data_only_incorrect_exteval.json`) -> Prepartion for easy access in the prompt\n",
    "\n",
    "The new merged data will be saved in `data_incorrect_merged.json` and will be used for the prompt to `GPT-4o` in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2225e38e-cb5a-472b-b808-b841d893f91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged JSON saved to data/merged/data_only_incorrect_merged.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "raw_data = \"data/data_only_incorrect.json\"\n",
    "exteval_data = \"data/scores/data_only_incorrect_exteval.json\"\n",
    "output_path = \"data/merged/data_only_incorrect_merged.json\"\n",
    "\n",
    "# read data\n",
    "with open(raw_data, 'r', encoding='utf-8') as f1:\n",
    "    data1 = json.load(f1)\n",
    "\n",
    "with open(exteval_data, 'r', encoding='utf-8') as f2:\n",
    "    data2 = json.load(f2)\n",
    "\n",
    "# result dictionary for the new json\n",
    "merged_data = {}\n",
    "\n",
    "# Merging of the data\n",
    "for key, value2 in data2.items():\n",
    "    if key in data1:  # check if the key is in both files\n",
    "        value1 = data1[key]\n",
    "        \n",
    "        # create new structure\n",
    "        merged_entry = {\n",
    "            **value2,  # gets all fields from the second json\n",
    "            \"summary\": value1.get(\"summary\"),\n",
    "            \"document\": value1.get(\"document\"),\n",
    "            \"summary_for_annotation\": value1.get(\"summary_for_annotation\"),\n",
    "            \"document_for_annotation\": value1.get(\"document_for_annotation\")\n",
    "        }\n",
    "        \n",
    "        # save inside new json\n",
    "        merged_data[key] = merged_entry\n",
    "\n",
    "# save completed new json\n",
    "with open(output_path, 'w', encoding='utf-8') as output_file:\n",
    "    json.dump(merged_data, output_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Merged JSON saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702edcf5-fef2-4cb9-b8cc-4647b38ced3b",
   "metadata": {},
   "source": [
    "### Step 3b: Combine incorrect data (`data_only_incorrect.json`) with their exteval scores (`data_only_incorrect_exteval_modified.json`) -> Prepartion for easy access in the prompt\n",
    "\n",
    "The new merged data will be saved in `data_incorrect_merged_modified.json` and will be used for the prompt to `GPT-4o` in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cb0c756-a98b-42a9-a687-92761a8bf3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged JSON saved to data/merged/data_only_incorrect_merged_modified.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "raw_data = \"data/data_only_incorrect.json\"\n",
    "exteval_modified_data = \"data/scores/data_only_incorrect_exteval_modified.json\"\n",
    "output_path = \"data/merged/data_only_incorrect_merged_modified.json\"\n",
    "\n",
    "# read_data\n",
    "with open(raw_data, 'r', encoding='utf-8') as f1:\n",
    "    data1 = json.load(f1)\n",
    "\n",
    "with open(exteval_modified_data, 'r', encoding='utf-8') as f2:\n",
    "    data2 = json.load(f2)\n",
    "\n",
    "# result dictionary for the new json\n",
    "merged_data = {}\n",
    "\n",
    "# Merging of the data\n",
    "for key, value2 in data2.items():\n",
    "    if key in data1:  # check if the key is in both files\n",
    "        value1 = data1[key]\n",
    "        \n",
    "        # create new structure\n",
    "        merged_entry = {\n",
    "            **value2, # gets all fields from the second json\n",
    "            \"summary\": value1.get(\"summary\"),\n",
    "            \"document\": value1.get(\"document\"),\n",
    "            \"summary_for_annotation\": value1.get(\"summary_for_annotation\"),\n",
    "            \"document_for_annotation\": value1.get(\"document_for_annotation\")\n",
    "        }\n",
    "        \n",
    "        # save inside new json\n",
    "        merged_data[key] = merged_entry\n",
    "\n",
    "# save completed new json\n",
    "with open(output_path, 'w', encoding='utf-8') as output_file:\n",
    "    json.dump(merged_data, output_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Merged JSON saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ec3d72-e3e2-4927-afc6-51852e6fed43",
   "metadata": {},
   "source": [
    "### Step 4: Call `GPT-4o` for every entry inside the `data_only_incorrect_merged.json` file with the prompt mask\n",
    "\n",
    "For every entry (535 entries) a call to `GPT-4o` will be made to get a new extractive summary which will be saved in a new file called `data_new.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b43c8808-eb60-4618-be11-55cc7cb85dcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_api*****here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m exteval_scores \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorCorefEval\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncomCorefEval\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncomDiscoEval\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentiBias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.15\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverallScore\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.2\u001b[39m }\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#Create the request\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a highly knowledgeable assistant trained in extracti\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mve summarization and evaluation.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                \u001b[49m\u001b[43moriginal_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moriginal_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m                \u001b[49m\u001b[43mextractive_summary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextractive_summary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m                \u001b[49m\u001b[43mexteval_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexteval_scores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#Print the answer\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/openai/resources/chat/completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    826\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    828\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/openai/_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1277\u001b[0m     )\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/openai/_base_client.py:1059\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1058\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1062\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1063\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1067\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1068\u001b[0m )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_api*****here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"your_api_key_here\")\n",
    "\n",
    "# Create the prompt\n",
    "prompt = \"\"\"\n",
    "You are an expert AI assistant specializing in extractive summarization and its evaluation using EXTEVAL. \n",
    "EXTEVAL is a system designed to assess extractive summaries' faithfulness by identifying issues in four error categories:\n",
    "\n",
    "1. **Incorrect Coreference (INCORCOREFEVAL):** Incorrect mapping of pronouns or noun phrases to their antecedents.\n",
    "2. **Incomplete Coreference (INCOMCOREFEVAL):** Missing or unclear antecedents for references in the text.\n",
    "3. **Incorrect Discourse (INCOMDISCOEVAL):** Faulty or misleading discourse relationships, such as inappropriate use of conjunctions or connectors.\n",
    "4. **Sentiment Bias (SENTIBIAS):** Misalignment of sentiments between the original text and the summary.\n",
    "\n",
    "Each category has a corresponding sub-metric (INCORCOREFEVAL, INCOMCOREFEVAL, INCOMDISCOEVAL, SENTIBIAS) that provides a score between 0 and 1. \n",
    "Scores closer to 1 indicate the presence of significant errors. The overall EXTEVAL score is a weighted average reflecting these metrics.\n",
    "\n",
    "### Task\n",
    "I will provide:\n",
    "- The **original document**\n",
    "- The **extractive summary**\n",
    "- EXTEVAL scores.\n",
    "\n",
    "Your job:\n",
    "1. Identify and revise problematic areas in the extractive summary to address the specific EXTEVAL metrics.\n",
    "2. Ensure the corrected extractive summary is faithful, coherent, and free from bias, fully resolving the identified errors.\n",
    "\n",
    "### Response Format\n",
    "Respond in this JSON format:\n",
    "```json\n",
    "{{\n",
    "    \"corrected_extractive_summary\": \"<your revised summary here>\",\n",
    "    \"justifications\": {{\n",
    "        \"IncorCorefEval\": \"<details of corrections made>\",\n",
    "        \"IncomCorefEval\": \"<details of corrections made>\",\n",
    "        \"IncomDiscoEval\": \"<details of corrections made>\",\n",
    "        \"SentiBias\": \"<details of corrections made>\"\n",
    "    }}\n",
    "}}\n",
    "```\n",
    "\n",
    "### Inputs\n",
    "Here is the original document: {original_text}\n",
    "Here is the extractive summary: {extractive_summary}\n",
    "Here are the EXTEVAL scores: {exteval_scores}\n",
    "\n",
    "Use the provided inputs to produce a corrected extractive summary and detailed justifications for each correction. \"\"\"\n",
    "\n",
    "# Example data\n",
    "original_text = \"Insert the full original document here...\" \n",
    "extractive_summary = \"Insert the problematic extractive summary here...\" \n",
    "exteval_scores = { \"IncorCorefEval\": 0.2, \"IncomCorefEval\": 0.3, \"IncomDiscoEval\": 0.1, \"SentiBias\": 0.15, \"OverallScore\": 0.2 }\n",
    "\n",
    "# Create the request\n",
    "completion = client.chat.completions.create( \n",
    "    model=\"gpt-4\", messages=[ \n",
    "        {\"role\": \"system\", \"content\": \"You are a highly knowledgeable assistant trained in extracti've summarization and evaluation.\"}, \n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": prompt.format( \n",
    "                original_text=original_text, \n",
    "                extractive_summary=extractive_summary, \n",
    "                exteval_scores=exteval_scores)\n",
    "        }\n",
    "    ] \n",
    ")\n",
    "\n",
    "# Print the answer\n",
    "print(completion.choices[0].message[\"content\"])\n",
    "\n",
    "\n",
    "### Key Points from the prompt:\n",
    "# 1. **Explicit Definitions**: Incorporated EXTEVAL’s detailed error metrics (coreference, discourse, and sentiment bias) based on the paper.\n",
    "# 2. **Actionable Guidelines**: Clear instructions for correcting errors aligned with the EXTEVAL framework.\n",
    "# 3. **Justification Requirement**: Added a section to justify how each specific metric’s issues were resolved, making the output more transparent and evaluative.\n",
    "# 4. **Standardized JSON Output**: Provides a machine-readable format for integrating corrections into larger pipelines.\n",
    "# This refined prompt ensures precise alignment with EXTEVAL's framework while maintaining clear and actionable guidance for improving summaries. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172548bc-2d5d-4dfd-8089-8fc443892278",
   "metadata": {},
   "source": [
    "### Step 4b: Call `GPT-4o` for every entry inside the `data_only_incorrect_merged_modified.json` file with the prompt mask with more information from ExtEval-Modified\n",
    "\n",
    "For every entry (535 entries) a call to `GPT-4o` will be made to get a new extractive summary which will be saved in a new file called `data_new.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e156de83-29f5-4c31-9ca4-66313abadf7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (389155630.py, line 45)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [3]\u001b[0;36m\u001b[0m\n\u001b[0;31m    exteval_scores = \"\"0_neusumm\": {\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"your_api_key_here\")\n",
    "\n",
    "# Create the prompt\n",
    "prompt = \"\"\"\n",
    "You are an expert AI assistant specializing in extractive summarization and evaluation using an advanced EXTEVAL framework. EXTEVAL assesses extractive summaries' faithfulness using the following error categories and metrics:\n",
    "\n",
    "### EXTEVAL Metrics\n",
    "1. **Incorrect Coreference (INCORCOREFEVAL):**\n",
    "   - **Definition:** Refers to incorrect mapping of pronouns or noun phrases to their antecedents.\n",
    "   - **Details Provided:** Count and list of specific instances, including:\n",
    "     - Problematic sentence(s)\n",
    "     - Specific mention(s)\n",
    "     - Error type (e.g., \"ambiguous pronoun\").\n",
    "\n",
    "2. **Incomplete Coreference (INCOMCOREFEVAL):**\n",
    "   - **Definition:** Indicates missing or unclear antecedents for references in the text.\n",
    "   - **Details Provided:** Count and list of specific instances, including:\n",
    "     - Problematic sentence(s)\n",
    "     - Specific mention(s)\n",
    "     - Error type (e.g., \"missing antecedent\").\n",
    "\n",
    "3. **Incorrect Discourse (INCOMDISCOEVAL):**\n",
    "   - **Definition:** Highlights faulty or misleading discourse relationships, such as inappropriate use of conjunctions or connectors.\n",
    "   - **Details Provided:** Count and list of specific instances, including:\n",
    "     - Problematic sentence(s)\n",
    "     - Specific discourse marker(s).\n",
    "\n",
    "4. **Sentiment Bias (SENTIBIAS):**\n",
    "   - **Definition:** Measures misalignment of sentiments between the source document and the summary.\n",
    "   - **Details Provided:**\n",
    "     - Absolute difference between document and summary sentiment.\n",
    "     - Average sentiment of the source document and summary.\n",
    "     - List of significant deviations with:\n",
    "       - Problematic sentence(s)\n",
    "       - Document sentiment\n",
    "       - Summary sentiment.\n",
    "\n",
    "5. **Overall EXTEVAL Score (EXTEVAL):**\n",
    "   - Represents a weighted aggregation of all sub-metrics, with higher values indicating greater issues.\n",
    "\n",
    "### Task\n",
    "I will provide:\n",
    "- The **original document**.\n",
    "- The **extractive summary**.\n",
    "- Detailed EXTEVAL scores with specific error details.\n",
    "\n",
    "Your responsibilities:\n",
    "1. **Analyze** the provided EXTEVAL scores and error details to identify the problematic areas in the summary.\n",
    "2. **Revise** the summary to address the identified issues, ensuring it is faithful, coherent, and sentimentally aligned with the source document.\n",
    "\n",
    "### Response Format\n",
    "Respond in this JSON format:\n",
    "```json\n",
    "{{\n",
    "    \"corrected_extractive_summary\": \"<your revised summary>\",\n",
    "    \"justifications\": {{\n",
    "        \"IncorCorefEval\": \"<summary of changes made>\",\n",
    "        \"IncomCorefEval\": \"<summary of changes made>\",\n",
    "        \"IncomDiscoEval\": \"<summary of changes made>\",\n",
    "        \"SentiBias\": \"<summary of changes made>\"\n",
    "    }}\n",
    "}}\n",
    "```\n",
    "\n",
    "### Inputs\n",
    "Here is the original document: {original_text}\n",
    "Here is the extractive summary: {extractive_summary}\n",
    "Here are the EXTEVAL scores: {exteval_scores}\n",
    "\n",
    "### Notes\n",
    "For Incorrect Coreference and Incomplete Coreference, revise pronouns or noun phrases to ensure accurate and clear references.\n",
    "For Incorrect Discourse, restructure sentences or replace discourse markers to create logical and coherent relationships.\n",
    "For Sentiment Bias, adjust phrasing or tone to align the summary's sentiment with the source document's sentiment distribution. \"\"\"\n",
    "\n",
    "# Example data\n",
    "original_text = \"Insert the full original document here...\" \n",
    "extractive_summary = \"Insert the problematic extractive summary here...\" \n",
    "exteval_scores = { \"0_neusumm\": \n",
    "                  { \"IncorCorefEval\": \n",
    "                   { \"count\": 0, \"details\": [] }, \n",
    "                   \"IncomCorefEval\": { \"count\": 0, \"details\": [] }, \n",
    "                   \"IncomDiscoEval\": { \"count\": 0, \"details\": [] }, \n",
    "                   \"SentiBias\": { \n",
    "                       \"absolute_difference\": 0.07061501783900892, \n",
    "                       \"doc_avg_sentiment\": 0.6347842197341379, \n",
    "                       \"summary_avg_sentiment\": 0.7053992375731468, \n",
    "                       \"significant_deviations\": \n",
    "                       [ \n",
    "                           { \"sentence_index\": 0, \"summary_sentiment\": 0.9926256537437439, \"document_avg_sentiment\": 0.6347842197341379 }, \n",
    "                           { \"sentence_index\": 1, \"summary_sentiment\": 0.9239406585693359, \"document_avg_sentiment\": 0.6347842197341379 } \n",
    "                       ] }, \n",
    "                   \"ExtEval\": 0.07061501783900892 }\n",
    "                 }\n",
    "\n",
    "\n",
    "# Create the request\n",
    "completion = client.chat.completions.create( \n",
    "    model=\"gpt-4\", \n",
    "    messages=[ \n",
    "        {\"role\": \"system\", \"content\": \"You are a highly knowledgeable assistant trained in extractive summarization and evaluation.\"}, \n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": prompt.format( \n",
    "                original_text=original_text, \n",
    "                extractive_summary=extractive_summary, \n",
    "                exteval_scores=exteval_scores )\n",
    "        } \n",
    "    ] \n",
    ")\n",
    "\n",
    "# Print the answer\n",
    "print(completion.choices[0].message[\"content\"])\n",
    "\n",
    "### Key Changes\n",
    "# 1. **Enhanced EXTEVAL Details**: Incorporated the extended EXTEVAL scores with **count, details, sentiment deviations**, and metrics for better analysis.\n",
    "# 2. **Actionable Justifications**: Added more context in the \"justifications\" section for each metric.\n",
    "# 3. **Clarity in Sentiment Bias**: Highlighted specific sentences with sentiment deviations, providing sentence-level sentiment values to aid targeted corrections.\n",
    "# 4. **Structured Error Insights**: Explicitly included `summary_sentence`, `mention`, `type`, and `discourse_marker` in the task instructions, helping the AI pinpoint corrections.\n",
    "# This refined prompt ensures detailed insights for correction while leveraging all the nuances in the new EXTEVAL data structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f753da7-5cdb-42a1-b5a5-f59413bbb9c7",
   "metadata": {},
   "source": [
    "### Step 5: Now the new and corrected summaries are evaluated by ExtEval to get new scores \n",
    "\n",
    "For this the new summaries need to be processed (`preprocess.py`) and after that evaluated (`exteval.py`). The new scores for the corrected summaries will be saved to `data_new_exteval.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1599d6-cd22-4c52-9dd2-188c94accc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79c09f2f-bbfc-4741-b8f6-892a9d84f8f8",
   "metadata": {},
   "source": [
    "### Step 5b: Now the new and corrected summaries are evaluated by ExtEval Modified to get new scores (for the summaries that were corrected with the extra information from ExtEval Modified)\n",
    "\n",
    "For this the new summaries need to be processed (`preprocess.py`) and after that evaluated (`exteval_modified.py`). The new scores for the corrected summaries will be saved to `data_new_exteval_modified.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f724ad2b-7c17-40e3-bd75-d04eb94bf3dd",
   "metadata": {},
   "source": [
    "### Step 6: The new ExtEval scores are now compared to the old ones to see the improvement \n",
    "\n",
    "This is the last step and the results will be visualised for the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735baa89-6cf7-478a-8dcc-e304be27dee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1142b4d-b948-4a97-9213-2162d2b32859",
   "metadata": {},
   "source": [
    "### Step 6: The new ExtEval Modified scores are now compared to the old ones to see the improvement and to the ones from the normal ExtEval correction without the extra informations\n",
    "\n",
    "This is the last step and the results will be visualised for the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab19b2-a399-43a3-bbc9-de2985a7d0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
